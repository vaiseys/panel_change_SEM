% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
]{article}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
  \usepackage{amssymb}
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[]{Minion Pro}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={A model-based method for detecting persistent cultural change using panel data},
  pdfauthor={Stephen Vaisey; Kevin Kiley},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1 \everypar{\setlength{\hangindent}{\cslhangindent}}\ignorespaces\fi
  % set entry spacing
  \ifnum #2 > 0
  \setlength{\parskip}{#2\baselineskip}
  \fi
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\title{A model-based method for detecting persistent cultural change using panel data\footnote{Thanks to Ken Bollen for inspiration and advice on this project.}}
\author{Stephen Vaisey\footnote{Professor of Sociology and Political Science, Duke University, \texttt{stephen.vaisey@duke.edu}.} \and Kevin Kiley\footnote{PhD Candidate, Department of Sociology, Duke University, \texttt{kevin.kiley@duke.edu}.}}
\date{2021-02-08}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Kiley and Vaisey (2020) recently published a method for assessing whether survey respondents appear to be changing their beliefs between waves or whether they instead appear to be repeating fixed responses with temporary local influences. This question is important because these processes reflect very different theoretical models of the evolution of ``personal culture'' (see Lizardo 2017). That is, if cultural beliefs are primarily public and responsive to external discourse, we should observe more updating as people respond to changes in their local environment. On the other hand, if cultural beliefs are primarily something learned early, then ``settled dispositions'' should be relatively resilient to change (see also Vaisey and Lizardo 2016).

In this paper, we build on Kiley and Vaisey (2020) and introduce an alternative method for distinguishing between cases where respondents appear be actively updating their responses and situations where respondents' responses appear to be settled. This method, based on structural equation modeling, provides a close fit to the theoretical models outlined in Kiley and Vaisey (2020) and provides even stronger support for their claim that most cultural beliefs reflect settled dispositions developed prior to adulthood.

\hypertarget{background}{%
\section{Background}\label{background}}

Kiley and Vaisey (2020, hereafter KV) distinguish between two main models of cultural change implied in the literature: the \emph{active updating model} and the \emph{settled dispositions model}. The assumptions of each model are represented in Figure 1. The active updating model assumes that shocks affecting a person's response to a question at one point in time persist to the next time period, while the settled dispositions model assumes that shocks do not persist.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{KVimage} 

}

\caption{Theoretical Models}\label{fig:mods}
\end{figure}

KV's goal is to develop a method that can distinguish between the two processes. They proceed by estimating the following equation on three-wave panel data:

\begin{equation}
  E(y_{i3}) = \alpha + \phi\beta y_{i2} + (1-\phi)\beta y_{i1} \label{eq:KVM}
\end{equation}

The intuition behind Equation \eqref{eq:KVM} is that, if people are updating their beliefs, survey responses that are closer in time (e.g., wave 1 and wave 2) should be more similar than responses that are more distant in time (wave 1 and wave 3). The \(\phi\) parameter indicates the relative weight given to the more proximate wave 2 response (\(\phi\)) and the more distal wave 1 response (\(1-\phi\)). As \(\phi\) approaches 1, wave 2 becomes more informative about wave 3 and wave 1 becomes less informative about wave 3, suggesting persistent change between waves. As \(\phi\) approaches .5, however, both prior waves are assigned equal weight, suggesting that the answers reflect a persistent disposition to answer the question in a particular way.\footnote{The \(\beta\) parameter reflects the extent to which wave 3 is predictable from \emph{any} combination of wave 1 and wave 2. Questions with low \(\beta\) are simply ``noisy.''}

Estimating this model on 183 variables from the 2006-2014 GSS panels, KV find that about 40 percent of the variables show no evidence of active updating, and most of the remainder show only weak evidence of active updating. Although they point out several exceptions (e.g., some questions about gay rights, where attitudes do appear to be changing over the study period) they conclude that the settled dispositions model is a better default for thinking about public opinion among adults.

\hypertarget{an-alternative-method}{%
\section{An alternative method}\label{an-alternative-method}}

\hypertarget{from-theoretical-to-statistical-models}{%
\subsection{From theoretical to statistical models}\label{from-theoretical-to-statistical-models}}

The alternative method we propose uses structural equation modeling to implement the theoretical graphs more directly. By estimating the model this way, we can compare a wide variety of model specifications that have different theoretical implications (see Bollen and Brand 2010). For example, we could specify the core graph of the settled dispositions model as follows:

\begin{eqnarray}
  y_{i1} = \alpha_1 + U_i + \epsilon_{i1} \\ 
  y_{i2} = \alpha_2 + U_i + \epsilon_{i2} \notag \\
  y_{i3} = \alpha_3 + U_i + \epsilon_{i3} \notag
\end{eqnarray}

From this basic version, we can add further constraints. For example we can constrain \(\alpha_1 = \alpha_2 = \alpha_3\) if we are willing to assume that the mean response is the same at all waves. And we could constrain \(\sigma^2_{\epsilon_1} = \sigma^2_{\epsilon_2} = \sigma^2_{\epsilon_3}\) if we are willing to assume that the variance of the responses does not change over time.

This is not the place for a general overview of structural equation modeling (Bollen 1989; see Kline 2015 for an accessible introduction). But the basic intuition in the three-wave case is that we are attempting to reconstruct 9 observed elements from the data (3 means, 3 variances, and 3 covariances) using a simpler model with fewer than 9 parameters. For example, if we make the assumptions in Equation (2), including the equality constraints in the following paragraph, we can estimate a model that has only 3 parameters: one value of \(\alpha\) (shared by all waves), one \(\sigma^2_{\epsilon}\) (shared by all waves), and one \(\sigma^2_U\). Here \(U\) is a ``latent variable,'' which, in this specification, simply means a person-specific ``error'' (or fixed effect) that gets added equally to a person's response at every wave. \(U_i\) reflects an individual's unchanging tendency to respond to a certain question the same way over the study period (a ``settled disposition'').

Using this model will not work well to reconstruct the observed data if the data were generated by a process that looks like the active updating model (on the left of Figure 1). We could instead estimate the following model:

\begin{eqnarray}
  y_{i3} = \alpha_3 + \rho y_{i2} + \epsilon_{i3} \\ 
  y_{i2} = \alpha_2 + \rho y_{i1} + \epsilon_{i2} \notag
\end{eqnarray}

Here we cannot make \(Y_1\) a dependent variable because we don't have its previous value (which would be \(Y_0\)). Therefore we can only use \(Y_1\) as a predictor. As above, we can make further simplifications if we want (e.g., \(\alpha_2 = \alpha_3\) or \(\sigma^2_{\epsilon_2} = \sigma^2_{\epsilon_3}\)). Using this fully simplified version, we are estimating a model with 5 parameters: one value of \(\alpha\) (shared by waves 2 and 3), one \(\sigma^2_{\epsilon}\) (shared by waves 2 and 3), the \(\rho\) autocorrelation parameter, and the mean and variance of \(Y_1\).

This model constrains \(\rho\) to be equal across waves. This implies that the rate of change between the two waves is equal, which comes with two implications. First, it assumes that the time between waves is equal. If waves are differently spaced, more time between waves is likely to equate to more active updating. This assumption is reasonable for the GSS panels, where surveys took place about two years apart.\footnote{Across the three panels, the average time between waves 1 and 2 is between 695 and 764 days, while the average time between waves 2 and 3 is between 692 and 743 days.} This might not be a reasonable assumption in other panels and can be loosened by adding a coefficient to \(\rho\) for the time since last wave.

Second, constraining \(\rho\) to be the same across waves implies that active updating happens by a linear secular trend. While this is likely a valid assumption for many questions we explore in the GSS, there are questions where opinions likely change discontinuously and in durable ways around specific dates and events. In the GSS panels, these questions include confidence in various branches of the government, which might change as a result of elections or high-profile political events, and confidence in financial institutions, belief in the ability to find a job, and subjective socioeconomic status, which might change in response to the onset of the Great Recession.\footnote{Despite the (potentially erroneous) assumption of linear updating, these questions still prefer the active updating model in relevant windows in the analysis below.}

In our framework, \(\rho\) should be thought of as a detector of whether any active updating happens in the panel window, rather than as a measure of the rate of active updating over time. If any updating happens in the panel window, \(\rho\) will tend to be non-zero. However, we cannot rule out the possibility that all attitudes can demonstrative durable updating under certain circumstances, only whether they demonstrate updating in our study window. We return to this point in the discussion below.

If \(Y_t\) were always measured perfectly, we could simply compare the penalized likelihoods (e.g., Bayesian Information Criteria) of the two models to see which is more likely to be the true model given the data (Bollen et al. 2014). Unfortunately, most GSS items likely contain some measurement error. Any measurement bias -- the systematic tendency for an item to over- or underestimate a person's ``true'' value -- will induce error correlations between waves that have no basis in the causal process. Thus \(U_i\) in Equation (2) represents both settled dispositions and respondent-specific measurement bias.

For this reason, the most reasonable specification of the active updating model combines features of equations (2) and (3), as follows:

\begin{eqnarray}
  y_{i3} = \alpha_3 + \rho y_{i2} + U_i + \epsilon_{i3} \\ 
  y_{i2} = \alpha_2 + \rho y_{i1} + U_i + \epsilon_{i2} \notag \\
  \text{Cov}(U,Y_1) = \tau \notag
\end{eqnarray}

Adding \(U\) to equation (4) allows for systematic correlations between the wave 2 and wave 3 responses due to measurement bias or error.\footnote{Unfortunately, in the three-wave case there's no way to distinguish systematic measurement bias or error from true person-level stable differences as components of \(U\) without additional untestable assumptions.} Estimating \(\tau\), the covariance between \(U\) and \(Y_1\), reflects that \(U\) and \(Y_1\) share common unobserved causes (e.g., measurement bias, values of the pre-survey \(Y_0\)).

The most straightforward\footnote{We could specify an even more parsimonious version of the settled dispositions model by estimating Equation (2) with the equality assumptions discussed in the text. This would effectively be estimating a confirmatory factor analysis on \(Y_t\). This would only require three parameters. We will revisit this in Section 4.2.} way to compare models is to specify them as special cases of a more general model. Figure 2 shows the basic model.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{figure2} 

}

\caption{General Model}\label{fig:unnamed-chunk-1}
\end{figure}

We have three basic choices to make:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Do we allow wave-to-wave updating of responses (estimate \(\rho\))?
\item
  Do we allow for settled dispositions and systematic bias (estimate \(\sigma^2_U\) and \(\tau\))?
\item
  Do we allow wave-to-wave changes in the mean response (estimate \(\alpha_2\) and \(\alpha_3\) separately) or assume no aggregate change (\(\alpha_2 = \alpha_3\))?
\end{enumerate}

Crossing these three binary choices would normally lead to 8 candidate models. However, we exclude from consideration models that contain neither updating nor settled dispositions because no theoretical perspective argues for them. This leaves us with six models, shown below.

\begin{longtable}[]{@{}lcccc@{}}
\toprule
Model & \(\sigma^2_U\), \(\tau\) & \(\rho\) & \(\alpha_t\) & \# parameters\tabularnewline
\midrule
\endhead
AUM1 & 0 & free & = & 5\tabularnewline
AUM2 & 0 & free & free & 6\tabularnewline
AUM3 & free & free & = & 7\tabularnewline
AUM4 & free & free & free & 8\tabularnewline
SDM1 & free & 0 & = & 6\tabularnewline
SDM2 & free & 0 & free & 7\tabularnewline
\bottomrule
\end{longtable}

For any given three-wave panel, we can compare the fit of these models against each other to help determine which of the models is most likely to have generated the data.

\hypertarget{advantages-of-the-approach}{%
\subsection{Advantages of the approach}\label{advantages-of-the-approach}}

Kiley and Vaisey (2020) also compare estimates using Equation (1) with and without constraints to adjudicate between the active updating and settled dispositions accounts. The approach we outline here is the same in spirit but different in the details. The main difference is that KV compare models based solely on how well they ``predict'' the Wave 3 response. Using structural equation models allows comparing the fit of the model to \emph{all} the observed data, not just the final response. For example, the KV model has no leverage in cases where respondents give the same response in waves 1 and 2, but a different response in wave 3, while the model presented here does.

To oversimplify slightly, the models presented here essentially adjudicate whether people are equally likely to deviate from their baseline response in all waves, which would be evidence of the settled dispositions model, or whether waves 1 and 3 are more likely than wave 2 to be deviations, which would be evidence of persisting changes and active updating.

An additional advantage of this approach is that can be more easily extended to panel data sets that include a larger number of waves than the model presented in KV. While three waves is the minimum number required to adjudicate the two theoretical approaches outlined above, and what we focus on in this paper, adding more waves can help adjudicate the two theoretical models under a wider array of assumptions.

\hypertarget{analytic-strategy}{%
\subsection{Analytic strategy}\label{analytic-strategy}}

We use the same 183 variables and three panels of the General Social Survey as Kiley and Vaisey (2020). Rather than pool the panels as they do, we estimate models separately on each one. Most variables appear in all three panels but 6 are measured in only one panel and one is measured in two panels. This gives us 536 total three-wave data sets.

For each of the 536 datasets, we estimate all 6 of the candidate models. We then compare fits using the Bayesian Information Criterion (BIC, see Raftery 1995; Bollen et al. 2014). In order to make the best case possible for each theoretical model, we will compare the best-fitting of the four AUM models with the best-fitting of the two SDM models. In cases where the BIC difference between the two ``finalist'' models is less than 2, we consider the evidence inconclusive (Raftery 1995; Bollen et al. 2014).

The approach is quite conservative, favoring the active updating model over the settled dispositions model when there is meaningful evidence that some amount of people in the sample are making durable changes in opinion or behavior. This should not be taken as evidence that \emph{many} people in the population are making durable changes, only that there is any evidence of durable change at all.

\hypertarget{results}{%
\section{Results}\label{results}}

\hypertarget{bic-comparisons}{%
\subsection{BIC comparisons}\label{bic-comparisons}}

Figure \ref{fig:winners} shows the results of these comparisons for all 536 variable-panels. One of the two SDM models is preferred for 71\% of cases, with one of the four AUM models preferred in 16\% of cases. The remaining cases are inconclusive.

\begin{figure}

{\centering \includegraphics{ms_files/figure-latex/winners-1} 

}

\caption{Preferred Models according to BIC Comparison}\label{fig:winners}
\end{figure}

If we look at only variables measured in all three panels, we can also compare the number of variables where all three agree. There are 69 variables that unanimously point to the SDM and only 3 that unanimously favor the AUM. The three unanimous AUM variables are \texttt{news} (reading a newspaper), \texttt{owngun} (having a gun in your home), and \texttt{socbar} (going to a bar or tavern). The presence of \texttt{owngun} on this list is promising because we \emph{know} that physical objects act according to an active updating model -- when you buy a gun, it stays in your house until you get rid of it.

\hypertarget{goodness-of-fit}{%
\subsection{Goodness-of-fit}\label{goodness-of-fit}}

Almost all (99.5 percent) of the preferred SDM models have acceptable fits (RMSEA \textless{} .08). But we can put the SDM to an even stronger test by estimating a model that assumes no updating across waves \emph{and} no changes in the means (i.e., no period effects). This is the model implied by Equation (2) and is equivalent to a simple confirmatory factor analysis with just three parameters: one value of \(\alpha\) (shared by all waves), one \(\sigma^2_{\epsilon}\) (shared by all waves), and one \(\sigma^2_U\). In essence, this model assumes that each wave is a report of a fixed quantity determined before the time of the study.

Estimating this model shows that it fits 83.4 percent of the variable-panels acceptably (RMSEA \textless{} .08) and 53.4 percent of the variable-panels well (RMSEA \textless{} .05). Figure 4 shows the overall distribution of RMSEA values. We don't want to take these conventional cutoffs too literally (see Barrett 2007), but altogether these results indicate that the majority of GSS items are highly compatible with the settled dispositions model.

\begin{figure}
\centering
\includegraphics{ms_files/figure-latex/cfa-1.pdf}
\caption{\label{fig:cfa}Distribution of Fit Values for Simple CFA}
\end{figure}

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

Building on Kiley and Vaisey (2020), we have presented a model-based approach to estimating whether the pattern of attitude and behavior change in the population should be best thought of as following a \emph{settled dispositions} model, where people have stable baselines and change (if any) is temporary, or an \emph{active updating} model, where changes tend to persist. Using a set of structural equation models that formalize these theoretical processes under a variety of assumptions, we compared the best-fitting settled dispositions model to the best-fitting active updating model for each variable in each panel, a total of 536 variable-panel pairs. The overwhelming majority of variable-panels prefer the settled dispositions model, with 69 variables preferring the settled dispositions model in all panels and only three variables preferring the active updating model in all panels.

While we cannot account for attitudes and behaviors that are not measured here, these results suggest, consistent with KV, that a wide range of attitudes and behaviors tend to be settled by the time people are old enough to participate in surveys like the GSS. While this is not surprising since we examine the same set of questions as KV, it is important that different statistical assumptions lead to similar substantive conclusions.

It is important to note here that settled opinions does not necessarily mean stable (unchanging) opinions. People might change their responses from wave to wave, but the settled dispositions model assumes this change does not tend to persist, meaning it reflects temporary changes in opinion or measurement error.\footnote{Within the settled dispositions model, our method cannot distinguish between change that occurs because people lack opinions and are more or less guessing at random (Converse 1964), change that occurs because people are influenced by short-term messaging and other considerations (Zaller 1992), or changes that occurs because of other forms of measurement error (Ansolabehere, Rodden, and Snyder 2008; Alwin 2007). We assume that these short-term changes are some combination of these forces, which might vary by question.} There is little evidence of even a moderate amount of durable change in opinions in the medium-term (2-4 years). Perhaps even more striking, the results in Section 4.2 show that the majority of variables are consistent with no population-level change in attitudes or behaviors at all over the four-year period.

As noted above, the fact that most attitudes prefer the settled dispositions model in the panel window should not be taken to imply that settled attitudes cannot durably update if circumstances change. Consistent with previous work, the results presented here suggest that circumstances occasionally change and lead to durable attitude change. At the same time, our results suggest that the kinds of circumstantial change that lead to durable attitude change seem relatively rare, and seem confined to major public events. If local changes such as changes in social network composition do lead to durable updating in attitudes, these local changes are so rare as to be undetectable on most issues measured here.

On specific variables, the approach presented here occasionally suggests different conclusions than the approach presented in KV, as would be expected under models that make different assumptions, with the model presented here favoring the SDM model in more cases. There are two main reasons for these differences. First, KV pool their panels together, and the method favors the active updating model is any updating is present, meaning that if \emph{any} of the three panels show updating, the variable as a whole is likely to show updating. A second reason these differences emerge is because the model presented here uses slightly more data than the KV model. A person who gives the same response in waves 1 and 2 but a different response in wave 3 is mostly useless under the KV model but can factor into the calculation in the model presented here. Because variable-panels can switch from favoring the active updating model to favoring the settled dispositions model with the addition or subtraction of a few cases, this suggests that evidence of the AUM is very weak even when it is favored. In particular, when the AUM is favored, it is often because a very small proportion of the population is making durable changes. It is difficult to draw broader conclusions about these discrepancies, as they cut across both question substance and question structure.

While it would be impossible to discuss all 183 variables or 536 variable-panels in depth, there are some broad patterns worth highlighting. Figure \ref{fig:categories} plots the proportion of variable-panels preferring each model by subject material.\footnote{It should be kept in mind when comparing across subject areas that the questions in subject areas often have different structures, and the questions asked in each category should not be thought of as a random sample of issues in that domain.} KV's results suggest that issues related to civil liberties, gender, and social trust tend to be settled by the time people entered the the GSS. The method outlined above finds similar results, with 86 percent, 89 percent, and 91 percent of variable-panels in these categories, respectively, favoring the settled dispositions models. These are the three categories with the largest proportions of variable-panels favoring the settled dispositions model.

\begin{figure}

{\centering \includegraphics{ms_files/figure-latex/categories-1} 

}

\caption{Proportion of preferred models, by subject category}\label{fig:categories}
\end{figure}

Similarly, KV suggested that public behaviors were more likely to demonstrate active updating, since these behaviors receive social reinforcement that facilitates durable change. In the results presented here, social behaviors such as socializing at a bar and religious behaviors such as church attendance are the two categories that show the highest rates of active updating, with 41 percent and 50 percent of variable-panels in these categories, respectively, showing evidence of active updating.

Another issue worth touching on is variation across panels in favoring the settled dispositions or active updating models within the same question. Of the 176 questions that appear in all three panels, 110 either favor the settled dispositions model or are inconclusive in all three waves (with 69 clearly favoring active updating in all panels). However, 58 variables favor each model in at least one panel.

Some of these discrepancies are likely due to real changes in the social environment that only affect members of one panel. For example, several of the questions with divergent findings pertain to whether the federal government is spending too little, about right, or too much on various priorities. People's responses might be changing in response to changes in federal spending, changes in who controls the federal government, or changes in public messaging around these issues, which might only happen in certain years.

For questions that demonstrate active updating in at least one panel but have no obvious changing external referent (such as church attendance, religious activity, partisan identification, frequency of prayer, and support for marijuana legalization), durable change might be happening but occur at such low rates that finite samples using imperfect measures do not capture enough respondents undergoing durable change in a particular panel to favor the active updating model. Again, even on generally stable issues we expect some people in the population to be actively updating their behavior -- most people know an adult who has changed their opinion on some issue -- but this should be thought of as the exception.\footnote{One reason people can recall examples of people in their social networks who have changed beliefs and behaviors is because it is rare and tends to stick out.} Our results suggest that when we observe someone change their response to a survey question, the assumption should be that it will not be a permanent change.

This points to a limitation of both this approach and the one used in Kiley and Vaisey (2020). Neither approach can quantify the proportion of the sample that is undergoing active updating. It is not clear whether, for the variable-panels that show evidence active updating, there is a large or small proportion of respondents making durable changes.

The two approaches share additional limitations. Both approaches assume linearity in the variable being measured. If an outcome is measured on an ordinal scale such as a four-point Likert scale (strongly agree, agree, disagree, strongly disagree), a change from agree to strongly agree is treated the same as a change from disagree to agree, which might or might not be a reasonable assumption. Both approaches also rely on weights to account for differential non-response over the course of the panel. If the mechanism of non-response and active updating are both driven by some unobserved variable, then our results might under-estimate the probability of durable change. That being said, we have no reason to assume that non-response is more likely to be related to active updating than settled dispositions.

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

The approach presented here and the approach Kiley and Vaisey (2020) use attempt to adjudicate a similar theoretical question: are there more people reporting patterns that look like active updating than we would expect if people behaved according to a settled dispositions model? The difference between the two approaches are sets of assumptions about what counts as an active updating pattern and what counts as a settled dispositions pattern. The fact that different sets of assumptions reach the same substantive conclusion, even under tests very favorable to detecting active updating, strengthens the findings from KV and others (e.g., Vaisey and Lizardo 2016) that the settled dispositions model should be thought of as the dominant model for attitude behavior in adults.

These findings have clear implications for cultural sociology and public opinion research, favoring models of cultural change rooted in cohort replacement (Mannheim 1970; Ryder 1965) and those that place importance on early-life socialization over contemporary social environments (such as Bourdieu 1990). We believe that these findings are also relevant for research on cultural evolution (see Henrich 2015; Heyes 2018; Mesoudi 2016) because they place significant limits on the likely pace and mechanisms of cultural change. Cohort-based change will necessarily be slower than that implied by simple population models of social learning. This lag process allows cultural equilibria to be durable even when the contemporary information environment is changing (O'Connor 2019). We hope future research explores these links more directly.

\newpage

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\hypertarget{ref-alwin2007}{}%
Alwin, Alwin, Duane F. 2007. \emph{Margins of {Error}: {A Study} of {Reliability} in {Survey Measurement}}. {Hoboken, N.J.}: {John Wiley \& Sons}.

\leavevmode\hypertarget{ref-ansolabehere2008}{}%
Ansolabehere, Stephen, Jonathan Rodden, and James M. Snyder. 2008. {``The {Strength} of {Issues}: {Using Multiple Measures} to {Gauge Preference Stability}, {Ideological Constraint}, and {Issue Voting}.''} \emph{American Political Science Review} 102 (2): 215--32. \url{https://doi.org/10.1017/S0003055408080210}.

\leavevmode\hypertarget{ref-barrett2007}{}%
Barrett, Paul. 2007. {``Structural Equation Modelling: {Adjudging} Model Fit.''} \emph{Personality and Individual Differences}, Special issue on {Structural Equation Modeling}, 42 (5): 815--24. \url{https://doi.org/10.1016/j.paid.2006.09.018}.

\leavevmode\hypertarget{ref-bollen1989}{}%
Bollen, Kenneth A. 1989. \emph{Structural {Equations} with {Latent Variables}}. {New York}: {Wiley}.

\leavevmode\hypertarget{ref-bollen2010}{}%
Bollen, Kenneth A., and Jennie E. Brand. 2010. {``A {General Panel Model} with {Random} and {Fixed Effects}: {A Structural Equations Approach}.''} \emph{Social Forces} 89 (1): 1--34.

\leavevmode\hypertarget{ref-bollen2014}{}%
Bollen, Kenneth A., Jeffrey J. Harden, Surajit Ray, and Jane Zavisca. 2014. {``{BIC} and {Alternative Bayesian Information Criteria} in the {Selection} of {Structural Equation Models}.''} \emph{Structural Equation Modeling : A Multidisciplinary Journal} 21 (1): 1--19. \url{https://doi.org/10.1080/10705511.2014.856691}.

\leavevmode\hypertarget{ref-bourdieu1990}{}%
Bourdieu, Pierre. 1990. \emph{The {Logic} of {Practice}}. {Stanford, CA}: {Stanford University Press}.

\leavevmode\hypertarget{ref-converse1964}{}%
Converse, Philip E. 1964. {``The Nature of Belief Systems in Mass Publics (1964).''} In \emph{Ideology and Discontent}, edited by D. E. Apter, 18:206--61. {New York}: {Free Press}.

\leavevmode\hypertarget{ref-henrich2015}{}%
Henrich, Joseph. 2015. \emph{The {Secret} of {Our Success}: {How Culture Is Driving Human Evolution}, {Domesticating Our Species}, and {Making Us Smarter}}. {Princeton University Press}.

\leavevmode\hypertarget{ref-heyes2018}{}%
Heyes, Cecilia. 2018. {``Enquire Within: Cultural Evolution and Cognitive Science.''} \emph{Philosophical Transactions of the Royal Society B: Biological Sciences} 373 (1743): 20170051. \url{https://doi.org/10.1098/rstb.2017.0051}.

\leavevmode\hypertarget{ref-kiley2020}{}%
Kiley, Kevin, and Stephen Vaisey. 2020. {``Measuring {Stability} and {Change} in {Personal Culture Using Panel Data}.''} \emph{American Sociological Review} 85 (3): 477--506. \url{https://doi.org/10.1177/0003122420921538}.

\leavevmode\hypertarget{ref-kline2015}{}%
Kline, Rex B. 2015. \emph{Principles and {Practice} of {Structural Equation Modeling}, {Fourth Edition}}. Fourth edition. {New York}: {The Guilford Press}.

\leavevmode\hypertarget{ref-lizardo2017}{}%
Lizardo, Omar. 2017. {``Improving {Cultural Analysis}: {Considering Personal Culture} in Its {Declarative} and {Nondeclarative Modes}.''} \emph{American Sociological Review} 82 (1): 88--115. \url{https://doi.org/10.1177/0003122416675175}.

\leavevmode\hypertarget{ref-mannheim1970}{}%
Mannheim, Karl. 1970. {``The {Problem} of {Generations}.''} \emph{Psychoanalytic Review} 57: 378--404.

\leavevmode\hypertarget{ref-mesoudi2016}{}%
Mesoudi, Alex. 2016. {``Cultural {Evolution}: {A Review} of {Theory}, {Findings} and {Controversies}.''} \emph{Evolutionary Biology} 43 (4): 481--97. \url{https://doi.org/10.1007/s11692-015-9320-0}.

\leavevmode\hypertarget{ref-oconnor2019}{}%
O'Connor, Cailin. 2019. \emph{The {Origins} of {Unfairness}: {Social Categories} and {Cultural Evolution}}. {New York}: {Oxford University Press}.

\leavevmode\hypertarget{ref-raftery1995}{}%
Raftery, Adrian E. 1995. {``Bayesian {Model Selection} in {Social Research}.''} \emph{Sociological Methodology} 25 (3): 111--63.

\leavevmode\hypertarget{ref-ryder1965}{}%
Ryder, Norman B. 1965. {``The {Cohort} as a {Concept} in the {Study} of {Social Change}.''} \emph{American Sociological Review} 30 (6): 843--61. \url{https://doi.org/10.2307/2090964}.

\leavevmode\hypertarget{ref-vaisey2016}{}%
Vaisey, Stephen, and Omar Lizardo. 2016. {``Cultural {Fragmentation} or {Acquired Dispositions}? {A New Approach} to {Accounting} for {Patterns} of {Cultural Change}.''} \emph{Socius: Sociological Research for a Dynamic World} 2 (January): 2378023116669726. \url{https://doi.org/10.1177/2378023116669726}.

\leavevmode\hypertarget{ref-zaller1992}{}%
Zaller, John R. 1992. \emph{The {Nature} and {Origins} of {Mass Opinion}}. {New York}: {Cambridge University Press}.

\end{CSLReferences}

\end{document}
